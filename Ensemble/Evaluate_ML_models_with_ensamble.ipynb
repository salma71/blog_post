{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluate_ML_models_with ensamble.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky3f7bsd4LiO"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "sPXjm9dB4oT8",
        "outputId": "030c6e14-8243-4149-8b05-b268d2181f68"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b5e3b748-e80b-467c-af88-6c69345228f2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b5e3b748-e80b-467c-af88-6c69345228f2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"salmaeng\",\"key\":\"231d5b452cf64da4dc6c6ff6eb15b34a\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02lb1mWD4qjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbafff29-0ae5-40a0-b846-d33ea6fa9c59"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHLDAnkd4uJF"
      },
      "source": [
        "\n",
        "#Make directory named kaggle and copy kaggle.json file there.\n",
        "#Change the permissions of the file.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZZCFXJ74v9r",
        "outputId": "15d34163-c045-4c0a-b4e7-a12fc4791bae"
      },
      "source": [
        "!kaggle datasets download -d uciml/pima-indians-diabetes-database"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pima-indians-diabetes-database.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-6fLe_04y-p",
        "outputId": "e98766e8-eba8-41a8-e276-a66575b503bf"
      },
      "source": [
        "#unzip the folder\n",
        "!mkdir train\n",
        "!unzip pima-indians-diabetes-database.zip -d train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘train’: File exists\n",
            "Archive:  pima-indians-diabetes-database.zip\n",
            "replace train/diabetes.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: train/diabetes.csv      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydoA3G9i41PA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "69E1-rP55Vwg",
        "outputId": "943eb810-f926-486f-a129-e26e69fdc233"
      },
      "source": [
        "# load the data\n",
        "data = pd.read_csv('/content/train/diabetes.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5sfKpQ1G8S0",
        "outputId": "a693c27e-0dba-4df2-fa77-afbb0f1359a3"
      },
      "source": [
        "feature_columns = list(data.columns)\n",
        "feature_columns.remove('Outcome')\n",
        "feature_columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pregnancies',\n",
              " 'Glucose',\n",
              " 'BloodPressure',\n",
              " 'SkinThickness',\n",
              " 'Insulin',\n",
              " 'BMI',\n",
              " 'DiabetesPedigreeFunction',\n",
              " 'Age']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui57YV_WHQgj"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "fill_values = SimpleImputer(missing_values=0, strategy=\"mean\", copy=False)\n",
        "\n",
        "data[feature_columns] = fill_values.fit_transform(data[feature_columns])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn72b3XQHeFF",
        "outputId": "4fb9b317-a122-4a97-d425-d7539251fe07"
      },
      "source": [
        "for column in feature_columns:\n",
        "    print(\"============================================\")\n",
        "    print(f\"{column} ==> Missing zeros : {len(data.loc[data[column] == 0])}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============================================\n",
            "Pregnancies ==> Missing zeros : 0\n",
            "============================================\n",
            "Glucose ==> Missing zeros : 0\n",
            "============================================\n",
            "BloodPressure ==> Missing zeros : 0\n",
            "============================================\n",
            "SkinThickness ==> Missing zeros : 0\n",
            "============================================\n",
            "Insulin ==> Missing zeros : 0\n",
            "============================================\n",
            "BMI ==> Missing zeros : 0\n",
            "============================================\n",
            "DiabetesPedigreeFunction ==> Missing zeros : 0\n",
            "============================================\n",
            "Age ==> Missing zeros : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "gGI33GM9Hkl3",
        "outputId": "5c8717c8-5b84-41c5-d534-060a9d14c370"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>148.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>35.00000</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>85.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>29.00000</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>183.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>29.15342</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>89.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>23.00000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.494673</td>\n",
              "      <td>137.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>35.00000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction   Age  Outcome\n",
              "0     6.000000    148.0           72.0  ...                     0.627  50.0        1\n",
              "1     1.000000     85.0           66.0  ...                     0.351  31.0        0\n",
              "2     8.000000    183.0           64.0  ...                     0.672  32.0        1\n",
              "3     1.000000     89.0           66.0  ...                     0.167  21.0        0\n",
              "4     4.494673    137.0           40.0  ...                     2.288  33.0        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXhBTCk_5bgw"
      },
      "source": [
        "# Improve performance using ensambles\n",
        "\n",
        "Ensambles could boost the accuracy of the machine learning model.\n",
        "\n",
        "In this section, We will use Bagging ensamble method. Also, I we will use boosting ensamble methods such as Ada Boost and schochastic gradient boosting. Additionally, we will utilize voting ensamble methods to combine the predictions from multiple algorithms. \n",
        "\n",
        "So, let's dig!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgWb8ggN5kPm"
      },
      "source": [
        "# Combine models into ensamble predictions\n",
        "\n",
        "There are three popular methods to combine the predictions from different models. These are :\n",
        "\n",
        "- Bagging: The other name is [Bootstrap aggrigating](https://en.wikipedia.org/wiki/Bootstrap_aggregating). **B**ootstrap **agg**regat**ing** tends to build multiple models(usually from the same type) from different subsamples of the training dataset. \n",
        "\n",
        "- [Boosting](https://en.wikipedia.org/wiki/Boosting_(machine_learning)): is another technique to build multiple models (also from the same type); however each model learns to fix the prediction errors of the previous model in the sequence of models. It is mainly used to balance the bias and variance in the supervised machine learning models. It is an algorithm that converts weak learners into strong one. \n",
        "\n",
        "\n",
        "- Voting: It intended to build multiple models **from different types** an then it uses the statistical methods (mean for example) to combine predictions. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TBbDC8-9K3q"
      },
      "source": [
        "For this tutorial, I will utilize the pima indian diabetes from the UCI machine learning repository. In the colab notebook, I managed to fetch the data via kaggle API. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yg8KuiJ-a9P"
      },
      "source": [
        "# 1. Bagging Algorithm \n",
        "Bootstrap aggrigation or baggibg for short manages to take multiple samples with replacement for each sample from the training set. \n",
        "\n",
        "The final predictions are calculated by taking the average across the predictions generated by the submodels. \n",
        "\n",
        "There are three bagging models we might use: \n",
        "- Bagging decision trees\n",
        "- Random Forest\n",
        "- Extra Trees\n",
        "\n",
        "Bagging has its best performance with algorithms that have high variance. In the following example, we will develop the `BaggingClassifier()` with the classification and regression trees algorithm (`DecisionTreeClassifier()`) within sklearn package. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFlGBK90-ap4"
      },
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBw8uvfR5WTJ"
      },
      "source": [
        "# split the data into train and test\n",
        "X = data.iloc[:, :-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGA-raUOGMSz"
      },
      "source": [
        "y = data.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdUqyT7hGPsA",
        "outputId": "dd78a3fb-c9b2-4571-d21e-0bdc8ab9c2d7"
      },
      "source": [
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 8) (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "RU6O3JXz9y_c",
        "outputId": "8ec66d8a-6478-4496-d325-f15390535ea6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-159-5e47142ac477>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2141\u001b[0m                      random_state=random_state)\n\u001b[1;32m   2142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2143\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \"\"\"\n\u001b[1;32m   1328\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1657\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[1;32m   1660\u001b[0m                              \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m                              \u001b[0;34m\" number of groups for any class cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drE19MWq9m9U"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "\n",
        "def evaluate(model, X_train, X_test, y_train, y_test):\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    y_train_pred = model.predict(X_train)\n",
        "\n",
        "    print(\"TRAINIG RESULTS: \\n===============================\")\n",
        "    clf_report = pd.DataFrame(classification_report(y_train, y_train_pred, output_dict=True))\n",
        "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_train, y_train_pred)}\")\n",
        "    print(f\"ACCURACY SCORE:\\n{accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "    print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
        "\n",
        "    print(\"TESTING RESULTS: \\n===============================\")\n",
        "    clf_report = pd.DataFrame(classification_report(y_test, y_test_pred, output_dict=True))\n",
        "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_test_pred)}\")\n",
        "    print(f\"ACCURACY SCORE:\\n{accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "    print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfnGERtz-g7J"
      },
      "source": [
        "BaggingClassifier Parameters:\n",
        "\n",
        "`base_estimator` : The base estimator to fit on random \n",
        "subsets of the dataset. If None, then the base estimator is a decision tree.\n",
        "\n",
        "`n_estimators` : The number of base estimators in the ensemble.\n",
        "\n",
        "`max_samples` : The number of samples to draw from X to train each base estimator.\n",
        "\n",
        "`max_features` : The number of features to draw from X to train each base estimator.\n",
        "\n",
        "`bootstrap` : Whether samples are drawn with replacement. If False, sampling without replacement is performed.\n",
        "\n",
        "`bootstrap_features` : Whether features are drawn with replacement.\n",
        "\n",
        "`oob_score` : Whether to use out-of-bag samples to estimate the generalization error.\n",
        "\n",
        "`warm_start` : When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1IfiG6U9fhU",
        "outputId": "751047c1-e9f5-4605-f4c2-1e3ad67f0ba7"
      },
      "source": [
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "bagging_clf = BaggingClassifier(base_estimator=tree, n_estimators=1500, random_state=42)\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "evaluate(bagging_clf, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINIG RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[350   0]\n",
            " [  0 187]]\n",
            "ACCURACY SCORE:\n",
            "1.0000\n",
            "CLASSIFICATION REPORT:\n",
            "               0      1  accuracy  macro avg  weighted avg\n",
            "precision    1.0    1.0       1.0        1.0           1.0\n",
            "recall       1.0    1.0       1.0        1.0           1.0\n",
            "f1-score     1.0    1.0       1.0        1.0           1.0\n",
            "support    350.0  187.0       1.0      537.0         537.0\n",
            "TESTING RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[126  24]\n",
            " [ 38  43]]\n",
            "ACCURACY SCORE:\n",
            "0.7316\n",
            "CLASSIFICATION REPORT:\n",
            "                    0          1  accuracy   macro avg  weighted avg\n",
            "precision    0.768293   0.641791  0.731602    0.705042      0.723935\n",
            "recall       0.840000   0.530864  0.731602    0.685432      0.731602\n",
            "f1-score     0.802548   0.581081  0.731602    0.691814      0.724891\n",
            "support    150.000000  81.000000  0.731602  231.000000    231.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC1xtFFd-CnC"
      },
      "source": [
        "scores = {\n",
        "    'Bagging Classifier': {\n",
        "        'Train': accuracy_score(y_train, bagging_clf.predict(X_train)),\n",
        "        'Test': accuracy_score(y_test, bagging_clf.predict(X_test)),\n",
        "    },\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikKjFi0a-EMN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaQwJav0soj6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZhLDrwDHHHA"
      },
      "source": [
        "As shown, we got a good performance compared to the model we developed in the previous results of using normal methods. \n",
        "\n",
        "\n",
        "# 2. Random Forest \n",
        "\n",
        "Now, let's take a shot and try the Randomforest model. It works like the bagged decision tree class, however it involving reducing the correlation between individual classifiers. It only consider the random subset of features per split instead of following the greedy approach to pick the best split point. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trCbi9vgAKpu"
      },
      "source": [
        "`n_estimators`: The number of trees in the forest.\n",
        "criterion: The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
        "\n",
        "`max_depth`: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
        "\n",
        "`min_samples_split`: The minimum number of samples required to split an internal node.\n",
        "\n",
        "`min_samples_leaf`: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
        "\n",
        "`min_weight_fraction_leaf`: The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n",
        "max_features: The number of features to consider when looking for the best split.\n",
        "\n",
        "`max_leaf_nodes`: Grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.\n",
        "\n",
        "`min_impurity_decrease`: A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
        "\n",
        "`min_impurity_split`: Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.\n",
        "\n",
        "`bootstrap`: Whether bootstrap samples are used when building trees. If False, the whole datset is used to build each tree.\n",
        "\n",
        "`oob_score`: Whether to use out-of-bag samples to estimate the generalization accuracy.\n",
        "\n",
        "`warm_start` : When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbKibsBfAqMA",
        "outputId": "83361aba-e7d3-4be6-8223-4a9db70fc4ec"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state=42, n_estimators=1000)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "evaluate(rf_clf, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINIG RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[350   0]\n",
            " [  0 187]]\n",
            "ACCURACY SCORE:\n",
            "1.0000\n",
            "CLASSIFICATION REPORT:\n",
            "               0      1  accuracy  macro avg  weighted avg\n",
            "precision    1.0    1.0       1.0        1.0           1.0\n",
            "recall       1.0    1.0       1.0        1.0           1.0\n",
            "f1-score     1.0    1.0       1.0        1.0           1.0\n",
            "support    350.0  187.0       1.0      537.0         537.0\n",
            "TESTING RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[127  23]\n",
            " [ 38  43]]\n",
            "ACCURACY SCORE:\n",
            "0.7359\n",
            "CLASSIFICATION REPORT:\n",
            "                    0          1  accuracy   macro avg  weighted avg\n",
            "precision    0.769697   0.651515  0.735931    0.710606      0.728257\n",
            "recall       0.846667   0.530864  0.735931    0.688765      0.735931\n",
            "f1-score     0.806349   0.585034  0.735931    0.695692      0.728745\n",
            "support    150.000000  81.000000  0.735931  231.000000    231.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rueEeyLZA1r1"
      },
      "source": [
        "scores['Random Forest'] = {\n",
        "        'Train': accuracy_score(y_train, rf_clf.predict(X_train)),\n",
        "        'Test': accuracy_score(y_test, rf_clf.predict(X_test)),\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyhkLIi7A3Ow"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDUgDYrhJHJD"
      },
      "source": [
        "We got a less accuracy! that's because it is only considered a certain number of features to choose the best split. If we tried to reduce `num_feat`, the accuracy would increase, and if we omit that variable inside the §RandomForestClassifier()`, you would get almost the same result using the bagging decision tree approach. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAVwhsGYKGAV"
      },
      "source": [
        "# Extra trees\n",
        "It is a modification of bagging where random trees are built from samples of the training set. \n",
        "This class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lajz0SosBd5j"
      },
      "source": [
        "`ExtraTreeClassifier` Parameters:\n",
        "\n",
        "`n_estimators`: The number of trees in the forest.\n",
        "\n",
        "`criterion`: The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
        "\n",
        "`max_depth`: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
        "\n",
        "min_samples_split: The minimum number of samples required to split an internal node.\n",
        "\n",
        "min_samples_leaf: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least \n",
        "\n",
        "min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
        "\n",
        "min_weight_fraction_leaf: The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n",
        "max_features: The number of features to consider when looking for the best split.\n",
        "\n",
        "max_leaf_nodes: Grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.\n",
        "\n",
        "min_impurity_decrease: A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
        "\n",
        "min_impurity_split: Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.\n",
        "\n",
        "bootstrap: Whether bootstrap samples are used when building trees. If False, the whole datset is used to build each tree.\n",
        "\n",
        "oob_score: Whether to use out-of-bag samples to estimate the generalization accuracy.\n",
        "\n",
        "warm_start : When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-iTC5j_B3g2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw2emmnXKSuM",
        "outputId": "0a5ffa48-2839-470c-e08b-2e9569d2176f"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "ex_tree_clf = ExtraTreesClassifier(n_estimators=1000, max_features=7, random_state=42)\n",
        "ex_tree_clf.fit(X_train, y_train)\n",
        "evaluate(ex_tree_clf, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINIG RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[350   0]\n",
            " [  0 187]]\n",
            "ACCURACY SCORE:\n",
            "1.0000\n",
            "CLASSIFICATION REPORT:\n",
            "               0      1  accuracy  macro avg  weighted avg\n",
            "precision    1.0    1.0       1.0        1.0           1.0\n",
            "recall       1.0    1.0       1.0        1.0           1.0\n",
            "f1-score     1.0    1.0       1.0        1.0           1.0\n",
            "support    350.0  187.0       1.0      537.0         537.0\n",
            "TESTING RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[124  26]\n",
            " [ 32  49]]\n",
            "ACCURACY SCORE:\n",
            "0.7489\n",
            "CLASSIFICATION REPORT:\n",
            "                    0          1  accuracy   macro avg  weighted avg\n",
            "precision    0.794872   0.653333  0.748918    0.724103      0.745241\n",
            "recall       0.826667   0.604938  0.748918    0.715802      0.748918\n",
            "f1-score     0.810458   0.628205  0.748918    0.719331      0.746551\n",
            "support    150.000000  81.000000  0.748918  231.000000    231.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGUJ_udyCF_k"
      },
      "source": [
        "scores['Extra Tree'] = {\n",
        "        'Train': accuracy_score(y_train, ex_tree_clf.predict(X_train)),\n",
        "        'Test': accuracy_score(y_test, ex_tree_clf.predict(X_test)),\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlZ1rtvQK_EZ"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "# 2. Boosting \n",
        "This creates a sequence of models that tries to correct errors for the models preceding in the sequence. Once developed, the model make predictions that might be weighted by their accuracy. After that, the results are combined to create the final out prediction. There are two most common boosting ensemble machine learning algorithms:\n",
        "\n",
        "- AdaBoost \n",
        "It works by weighting the dataset instances by classifying difficulties allowing the algorithm to pay attention to them in the construction of the subsequent model in the sequence.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd8p3AoWDWtj"
      },
      "source": [
        "AdaBoostClassifier Params:\n",
        "\n",
        "base_estimator : The base estimator from which the boosted ensemble is built.\n",
        "\n",
        "n_estimators : The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early.\n",
        "\n",
        "learning_rate : Learning rate shrinks the contribution of each classifier by learning_rate. There is a trade-off between learning_rate and n_estimators.\n",
        "\n",
        "algorithm : If 'SAMME.R' then use the SAMME.R real boosting algorithm. base_estimator must support calculation of class probabilities. If 'SAMME' then use the SAMME discrete boosting algorithm. The SAMME.R algorithm typically converges faster than SAMME, achieving a lower test error with fewer boosting iterations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzCfCe9tDjA8",
        "outputId": "172c959b-a476-4a0d-c8ba-f22ec609a836"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_boost_clf = AdaBoostClassifier(n_estimators=30)\n",
        "ada_boost_clf.fit(X_train, y_train)\n",
        "evaluate(ada_boost_clf, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINIG RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[314  36]\n",
            " [ 49 138]]\n",
            "ACCURACY SCORE:\n",
            "0.8417\n",
            "CLASSIFICATION REPORT:\n",
            "                    0           1  accuracy   macro avg  weighted avg\n",
            "precision    0.865014    0.793103  0.841713    0.829059      0.839972\n",
            "recall       0.897143    0.737968  0.841713    0.817555      0.841713\n",
            "f1-score     0.880785    0.764543  0.841713    0.822664      0.840306\n",
            "support    350.000000  187.000000  0.841713  537.000000    537.000000\n",
            "TESTING RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[129  21]\n",
            " [ 36  45]]\n",
            "ACCURACY SCORE:\n",
            "0.7532\n",
            "CLASSIFICATION REPORT:\n",
            "                    0          1  accuracy   macro avg  weighted avg\n",
            "precision    0.781818   0.681818  0.753247    0.731818      0.746753\n",
            "recall       0.860000   0.555556  0.753247    0.707778      0.753247\n",
            "f1-score     0.819048   0.612245  0.753247    0.715646      0.746532\n",
            "support    150.000000  81.000000  0.753247  231.000000    231.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWmgy79eDnIF"
      },
      "source": [
        "scores['AdaBoost'] = {\n",
        "        'Train': accuracy_score(y_train, ada_boost_clf.predict(X_train)),\n",
        "        'Test': accuracy_score(y_test, ada_boost_clf.predict(X_test)),\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWqodAjuEJI2"
      },
      "source": [
        "Stochastic Gradient Boosting (also called Gradient Boosting Machines) are one of the most sophisticated ensemble techniques. It is also a technique that is proving to be perhaps of the the best techniques available for improving performance via ensembles.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUSIz1sTEPBk"
      },
      "source": [
        "GB builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage n_classes_ regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UyGfR7jEQUv"
      },
      "source": [
        "GradientBoostingClassifier Parameters:\n",
        "\n",
        "`loss` : loss function to be optimized. 'deviance' refers to deviance (= logistic regression) for classification with probabilistic outputs. For loss 'exponential' gradient boosting recovers the AdaBoost algorithm.\n",
        "\n",
        "learning_rate : learning rate shrinks the contribution of each tree by learning_rate. There is a trade-off between learning_rate and n_estimators.\n",
        "\n",
        "n_estimators : The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
        "\n",
        "subsample : The fraction of samples to be used for fitting the individual base learners. If smaller than 1.0 this results in Stochastic Gradient Boosting. subsample interacts with the parameter n_estimators. Choosing subsample < 1.0 leads to a reduction of variance and an increase in bias.\n",
        "\n",
        "criterion : The function to measure the quality of a split. Supported criteria are \"friedman_mse\" for the mean squared error with improvement score by Friedman, \"mse\" for mean squared error, and \"mae\" for the mean absolute error. The default value of \"friedman_mse\" is generally the best as it can provide a better approximation in some cases.\n",
        "\n",
        "min_samples_split: The minimum number of samples required to split an internal node.\n",
        "\n",
        "min_samples_leaf: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
        "\n",
        "min_weight_fraction_leaf: The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n",
        "\n",
        "max_depth: maximum depth of the individual regression estimators. The maximum depth limits the number of nodes in the tree. Tune this parameter for best performance; the best value depends on the interaction of the input variables.\n",
        "\n",
        "min_impurity_decrease: A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
        "\n",
        "min_impurity_split: Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.\n",
        "\n",
        "max_features: The number of features to consider when looking for the best split.\n",
        "\n",
        "max_leaf_nodes: Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.\n",
        "\n",
        "warm_start: When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just erase the previous solution.\n",
        "\n",
        "validation_fraction: The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if n_iter_no_change is set to an integer.\n",
        "\n",
        "n_iter_no_change: used to decide if early stopping will be used to terminate training when validation score is not improving. By default it is set to None to disable early stopping. If set to a number, it will set aside validation_fraction size of the training data as validation and terminate training when validation score is not improving in all of the previous n_iter_no_change numbers of iterations. The split is stratified.\n",
        "\n",
        "tol: Tolerance for the early stopping. When the loss is not improving by at least tol for n_iter_no_change iterations (if set to a number), the training stops.\n",
        "\n",
        "ccp_alpha: Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o63ijAUMbbt",
        "outputId": "53078b81-f749-4fa2-9d0f-b1ac9f69bbd5"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "grad_boost_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "grad_boost_clf.fit(X_train, y_train)\n",
        "evaluate(grad_boost_clf, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINIG RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[339  11]\n",
            " [ 26 161]]\n",
            "ACCURACY SCORE:\n",
            "0.9311\n",
            "CLASSIFICATION REPORT:\n",
            "                    0           1  accuracy   macro avg  weighted avg\n",
            "precision    0.928767    0.936047  0.931099    0.932407      0.931302\n",
            "recall       0.968571    0.860963  0.931099    0.914767      0.931099\n",
            "f1-score     0.948252    0.896936  0.931099    0.922594      0.930382\n",
            "support    350.000000  187.000000  0.931099  537.000000    537.000000\n",
            "TESTING RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[126  24]\n",
            " [ 37  44]]\n",
            "ACCURACY SCORE:\n",
            "0.7359\n",
            "CLASSIFICATION REPORT:\n",
            "                    0          1  accuracy   macro avg  weighted avg\n",
            "precision    0.773006   0.647059  0.735931    0.710032      0.728843\n",
            "recall       0.840000   0.543210  0.735931    0.691605      0.735931\n",
            "f1-score     0.805112   0.590604  0.735931    0.697858      0.729895\n",
            "support    150.000000  81.000000  0.735931  231.000000    231.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39f6syWcD_qp"
      },
      "source": [
        "scores['Gradient Boosting'] = {\n",
        "        'Train': accuracy_score(y_train, grad_boost_clf.predict(X_train)),\n",
        "        'Test': accuracy_score(y_test, grad_boost_clf.predict(X_test)),\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnBoHNmEEq58"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz2Kceq0fdMo"
      },
      "source": [
        "- Stochastic Gradient Boosting (Gradient Boosting Machines) \n",
        "\n",
        "Although it considered the most sophisticated ensemble technique, it is considered to be the best technique to improve the machine learning performance via ensamble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZz35FX2gusH"
      },
      "source": [
        "# 3. Voting Ensemble\n",
        "It is simple and easy to implement. First, it creates a two standalone models(may be more depending on the use case) from the dataset. Then, a voting classifier is used to wrap the models and average the predictions of the submodels when introducing the new data. \n",
        "\n",
        "Aalthough the predictions of the submodels have weights, unfortunately, we cannot adjust those weights to increase the performance. Those weights may be adjusted using different approach which is **[Stacked Aggregation](https://en.wikipedia.org/wiki/Ensemble_learning#Stacking)**. Unfortunately, this algorithm is not included within the sklearn library yet. You can either implement it from scratch by yourself or use the [ML-Ensemble library](http://ml-ensemble.com/). \n",
        "\n",
        "> [H2O library](http://docs.h2o.ai/h2o-tutorials/latest-stable/tutorials/ensembles-stacking/index.html) offers a decent API to implement the Stack Aggregation ensemble in R, you can check the documentation [here](http://docs.h2o.ai/h2o-tutorials/latest-stable/tutorials/ensembles-stacking/index.html). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89AuQh9_GTw9"
      },
      "source": [
        "VotingClassifier :\n",
        "\n",
        "estimators : Invoking the fit method on the VotingClassifier will fit clones of those original estimators that will be stored in the class attribute self.estimators_.\n",
        "\n",
        "voting : If 'hard', uses predicted class labels for majority rule voting. Else if 'soft', predicts the class label based on the argmax of the sums of the predicted probabilities, which is recommended for an ensemble of well-calibrated classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlIBwI_Qmr-l"
      },
      "source": [
        "In the following snippet, we combine three different ml algorithms and we will use the `VotingClassifier()` class within the sklearn to get max accuracy out of the models combined. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sb_WaV3GbWF",
        "outputId": "458c15ce-6d12-484a-f633-1601fa971907"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "estimators = []\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "estimators.append(('Logistic', log_reg))\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "estimators.append(('Tree', tree))\n",
        "\n",
        "svm_clf = SVC(gamma='scale')\n",
        "estimators.append(('SVM', svm_clf))\n",
        "\n",
        "voting = VotingClassifier(estimators=estimators)\n",
        "voting.fit(X_train, y_train)\n",
        "\n",
        "evaluate(voting, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINIG RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[328  22]\n",
            " [ 75 112]]\n",
            "ACCURACY SCORE:\n",
            "0.8194\n",
            "CLASSIFICATION REPORT:\n",
            "                    0           1  accuracy   macro avg  weighted avg\n",
            "precision    0.813896    0.835821  0.819367    0.824858      0.821531\n",
            "recall       0.937143    0.598930  0.819367    0.768037      0.819367\n",
            "f1-score     0.871182    0.697819  0.819367    0.784501      0.810812\n",
            "support    350.000000  187.000000  0.819367  537.000000    537.000000\n",
            "TESTING RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[135  15]\n",
            " [ 40  41]]\n",
            "ACCURACY SCORE:\n",
            "0.7619\n",
            "CLASSIFICATION REPORT:\n",
            "                    0          1  accuracy   macro avg  weighted avg\n",
            "precision    0.771429   0.732143  0.761905    0.751786      0.757653\n",
            "recall       0.900000   0.506173  0.761905    0.703086      0.761905\n",
            "f1-score     0.830769   0.598540  0.761905    0.714655      0.749338\n",
            "support    150.000000  81.000000  0.761905  231.000000    231.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNCrvgz5Gf6m"
      },
      "source": [
        "scores['Voting'] = {\n",
        "        'Train': accuracy_score(y_train, voting.predict(X_train)),\n",
        "        'Test': accuracy_score(y_test, voting.predict(X_test)),\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "jjsipu40GhDW",
        "outputId": "c8c94ec2-88d5-490a-866e-bfc1a687d789"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "scores_df = pd.DataFrame(scores)\n",
        "# with plt.xkcd():\n",
        "\n",
        "scores_df.plot(kind='bar', figsize=(15, 8))\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ffa9cb62550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd1tUyvFme_Z",
        "outputId": "67675161-5007-4023-b042-8c2ebacf1afa"
      },
      "source": [
        "!kaggle datasets download -d vikrishnan/boston-house-prices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading boston-house-prices.zip to /content\n",
            "\r  0% 0.00/12.8k [00:00<?, ?B/s]\n",
            "\r100% 12.8k/12.8k [00:00<00:00, 21.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOZARcbHqLsm",
        "outputId": "b50f0c36-5948-495b-e2b1-f3e21a7a830f"
      },
      "source": [
        "#unzip the folder\n",
        "!mkdir boston\n",
        "!unzip boston-house-prices.zip -d boston"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  boston-house-prices.zip\n",
            "  inflating: boston/housing.csv      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2r3-NDe6qVea",
        "outputId": "30198d4a-e3eb-4e8f-b968-6f5c2b37d6e8"
      },
      "source": [
        "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
        "data = pd.read_csv('/content/boston/housing.csv', header=None, delimiter=r\"\\s+\", names=column_names)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>MEDV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV\n",
              "0  0.00632  18.0   2.31     0  0.538  ...  296.0     15.3  396.90   4.98  24.0\n",
              "1  0.02731   0.0   7.07     0  0.469  ...  242.0     17.8  396.90   9.14  21.6\n",
              "2  0.02729   0.0   7.07     0  0.469  ...  242.0     17.8  392.83   4.03  34.7\n",
              "3  0.03237   0.0   2.18     0  0.458  ...  222.0     18.7  394.63   2.94  33.4\n",
              "4  0.06905   0.0   2.18     0  0.458  ...  222.0     18.7  396.90   5.33  36.2\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juy5NswqqoO7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}